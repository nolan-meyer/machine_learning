---
output:
  pdf_document: default
  html_document: default
---
```{r hw3_setup, include=FALSE}
knitr::opts_chunk$set(echo=TRUE, eval=FALSE)
```

## Project Work {-}

(Note: This includes HW2 investigations plus a few tasks for dealing with non-linearity.)

**Goal:** Begin an analysis of your dataset to answer your **regression** research question.

<br>

**Collaboration:** Form a team (2-3 members) for the project and this part can be done as a team. Only one team member should submit a Project Work section. Make sure you include the full names of all of the members in your write up. 

<br>

**Data cleaning:** If your dataset requires any cleaning (e.g., merging datasets, creation of new variables), first consult the [R Resources page](r-resources.html) to see if your questions are answered there. If not, post on the #rcode-questions channel in our Slack workspace to ask for help. *Please ask for help early and regularly* to avoid stressful workloads.

<br>


**Required Analyses:**

1. **Initial investigation: ignoring nonlinearity (for now)**
    a. Use ordinary least squares (OLS) by using the `lm` engine and LASSO (`glmnet` engine) to build  a series of initial regression models for your quantitative outcome as a function of the predictors of interest. (As part of data cleaning, exclude any variables that you don't want to consider as predictors.)
        - You'll need two model specifications, `lm_spec` and `lm_lasso_spec` (you'll need to tune this one).
    b. For each set of variables, you'll need a `recipe` with the `formula`, `data`, and pre-processing steps
        - You may want to have steps in your recipe that remove variables with near zero variance (`step_nzv()`), remove variables that are highly correlated with other variables (`step_corr()`), normalize all quantitative predictors (`step_normalize(all_numeric_predictors())`) and add indicator variables for any categorical variables (`step_dummy(all_nominal_predictors())`).
        - These models should not include any transformations to deal with nonlinearity. You'll explore this in the next investigation.
    c. Estimate the test performance of the models using CV. Report and interpret (with units) the CV metric estimates along with a measure of uncertainty in the estimate (`std_error` is readily available when you used `collect_metrics(summarize=TRUE)`).
        - Compare estimated test performance across the models. Which models(s) might you prefer?
    d. Use residual plots to evaluate whether some quantitative predictors might be better modeled with nonlinear relationships.
    e. Which variables do you think are the most important predictors of your quantitative outcome? Justify your answer. Do the methods you've applied reach consensus on which variables are most important? What insights are expected? Surprising?
        - Note that if some (but not all) of the indicator terms for a categorical predictor are selected in the final models, the whole predictor should be treated as selected.
<br>

a & b.

```{r, eval = TRUE, include=FALSE}
# library statements 
# read in data
library(dplyr)
library(readr)
library(broom)
library(ggplot2)
library(tidymodels) 
library(tidyverse)
tidymodels_prefer() # Resolves conflicts, prefers tidymodel functions

set.seed(123)

basic_stats <- read_csv("Basic_Stats.csv")
qb_stats <- read_csv("Career_Stats_Passing.csv")
punt_return <- read_csv("Career_Stats_Punt_Return.csv")
punting <- read_csv("Career_Stats_Punting.csv")
receiving <- read_csv("Career_Stats_Receiving.csv")
kickers <- read_csv("Game_Logs_Kickers.csv")
oline_logs <- read_csv("Game_Logs_Offensive_Line.csv")
punters_logs <- read_csv("Game_Logs_Punters.csv")
qb_logs <- read_csv("Game_Logs_Quarterback.csv")
rb_logs <- read_csv("Game_Logs_Runningback.csv")
wrandte_logs <- read_csv("Game_Logs_Wide_Receiver_and_Tight_End.csv")
```

```{r}
# data cleaning
qb_stats <- qb_stats %>%
    select(-Position)
    
qb_stats <- qb_stats %>%
    rename("Rating" = "Passer Rating")

basic_stats <- basic_stats %>%
    rename("Team" = "Current Team")

basic_stats <- basic_stats %>%
    rename("hsloc" = "High School Location")

basic_stats <- basic_stats %>%
    rename("Weight" = "Weight (lbs)")

basic_stats <- basic_stats %>%
    rename("Height" = "Height (inches)")

basic_stats <- basic_stats %>%
    filter(Position == "QB")

qb_comb <- merge(qb_stats, basic_stats, by="Name")


qb_comb$`Passes Attempted`[which(qb_comb$`Passes Attempted` == '--')] = 0
qb_comb <- qb_comb %>%
  mutate(`Passes Attempted` = as.numeric(`Passes Attempted`)) %>% 
    mutate(`Games Played` = as.numeric(`Games Played`))

qb_comb <- qb_comb %>% select(-c(Number, `Years Played`))


qb_comb <- qb_comb %>% mutate(Experience = as.numeric(stringr::str_extract(Experience,'[0-9]+')))

qb_comb <- qb_comb %>% mutate(hsState = stringr::str_sub(hsloc,-2,-1))

qb_comb <- qb_comb %>% mutate(Conference = c("PAC-12", "PAC-12", "PAC-12", "PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12",
                                             "PAC-12", "PAC-12", "PAC-12", "PAC-12",
                                             "AAC", "AAC", "AAC",
                                             "Big 12", 
                                             "Big 12","Big 12","Big 12","Big 12","Big 12","Big 12",
                                             "Big 10", "Big 10", "Big 10", "Big 10", "Big 10", "Big 10", "Big 10", "Big 10", "Big 10", "Big 10", "Big 10", "Big 10", "Big 10", "Big 10", "Big 10", "Big 10",
                                             "Big 10", "Big 10", "Big 10", "Big 10", "Big 10", "Big 10", "Big 10", "Big 10", "Big 10", "Big 10", "Big 10", "Big 10", "Big 10", "Big 10", "Big 10", "Big 10", "Big 10",
                                             "ACC", "ACC",
                                             "ACC",
                                             "Mountain West", "Mountain West", "Mountain West",
                                             "PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12",
                                             "PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12",
                                             "Big 10",
                                             "Big 10","Big 10","Big 10","Big 10","Big 10",
                                             "SEC", "SEC", "SEC", "SEC", "SEC", "SEC", "SEC", "SEC", "SEC", "SEC", "SEC",
                                             "Big 12", "Big 12", "Big 12", "Big 12", "Big 12", "Big 12",
                                             "Big 12","Big 12","Big 12","Big 12","Big 12","Big 12","Big 12","Big 12",
                                             "CUSA", "CUSA", "CUSA", "CUSA", "CUSA",
                                             "Mountain West", "Mountain West", "Mountain West",
                                             "Ivy","Ivy","Ivy","Ivy","Ivy","Ivy","Ivy","Ivy","Ivy","Ivy","Ivy","Ivy",
                                             "Colonial Athletic Association","Colonial Athletic Association","Colonial Athletic Association","Colonial Athletic Association","Colonial Athletic Association","Colonial Athletic Association","Colonial Athletic Association","Colonial Athletic Association","Colonial Athletic Association",
                                             "PAC-12","PAC-12","PAC-12","PAC-12","PAC-12",
                                             "Big 12","Big 12","Big 12","Big 12","Big 12","Big 12",
                                             "Ohio Valley Conference", "Ohio Valley Conference", "Ohio Valley Conference",
                                             "ACC", "ACC", "ACC", "ACC",
                                             "PAC-12",
                                             "Big 12","Big 12","Big 12","Big 12","Big 12",
                                             "Big 10","Big 10","Big 10","Big 10","Big 10","Big 10","Big 10","Big 10","Big 10",
                                             "ACC", "ACC","ACC","ACC","ACC","ACC","ACC","ACC","ACC","ACC","ACC","ACC","ACC","ACC","ACC",
                                             "PAC-12",
                                             "Big 10","Big 10","Big 10","Big 10","Big 10","Big 10","Big 10","Big 10","Big 10",
                                             "PAC-12","PAC-12",
                                             "Pioneer Football League", "Pioneer Football League", "Pioneer Football League", "Pioneer Football League", "Pioneer Football League", "Pioneer Football League", "Pioneer Football League", "Pioneer Football League", "Pioneer Football League", "Pioneer Football League",
                                             "Big 10",
                                             "Big 12","Big 12","Big 12","Big 12",
                                             "Mountain West","Mountain West","Mountain West","Mountain West","Mountain West","Mountain West",
                                             "AAC","AAC","AAC","AAC","AAC",
                                             "PAC-12",
                                             "ACC","ACC","ACC","ACC","ACC","ACC",
                                             "PAC-12","PAC-12","PAC-12","PAC-12","PAC-12",
                                             "AAC",
                                             "SEC","SEC","SEC","SEC","SEC","SEC","SEC",
                                             "SEC","SEC","SEC","SEC","SEC","SEC","SEC","SEC","SEC","SEC","SEC","SEC","SEC",
                                             "PAC-12","PAC-12",
                                             "ACC", "ACC", "ACC", "ACC",
                                             "PAC-12","PAC-12",
                                             "SEC", "SEC", "SEC",
                                             "Southland Conference", "Southland Conference","Southland Conference","Southland Conference","Southland Conference","Southland Conference","Southland Conference","Southland Conference","Southland Conference","Southland Conference","Southland Conference","Southland Conference","Southland Conference","Southland Conference",
                                             "CUSA", "CUSA", "CUSA", "CUSA","CUSA","CUSA","CUSA","CUSA","CUSA","CUSA","CUSA","CUSA","CUSA", "Big 12",
                                             "Big 12","Big 12","Big 12","Big 12","Big 12","Big 12", "Big 10",
                                             "Big 10","Big 10","Big 10","Mountain West",
                                              "Mountain West", "Mountain West", "Mountain West", "PAC-12",
                                             "PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","ACC",
                                             "ACC", "ACC", "ACC", "SEC",
                                             "SEC","SEC","SEC","SEC","SEC","AAC",
                                             "AAC", "AAC","AAC","AAC","AAC","AAC","AAC","AAC","AAC","AAC","AAC","PAC-12",
                                             "PAC-12","PAC-12","PAC-12","PAC-12","PAC-12",
                                             "PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","Big 12",
                                             "Big 12", "ACC",
                                             "ACC","ACC","ACC","ACC","ACC","SEC",
                                             "ACC",
                                             "ACC","ACC","ACC","ACC","ACC","ACC","ACC","ACC","ACC","ACC","ACC","ACC","PAC-12",
                                             "PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","MAC",
                                             "MAC", "MAC","MAC","MAC","MAC","MAC","MAC","MAC","MAC","MAC","MAC","MAC","ACC",
                                             "ACC","ACC","ACC","ACC","ACC","ACC","ACC","ACC","PAC-12",
                                             "PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","ACC",
                                             "ACC","SEC",
                                             "Big 10",
                                             "Big 10","SEC",
                                             "SEC", "PAC-12",
                                             "PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","Big 12","Big 12","Big 12","Big 12",
                                             "SEC", "SEC", "SEC","SEC",
                                             "SEC","SEC","SEC","SEC","Big 10","Big 10","Big 10","Big 10",
                                             "Big 10","Big 10","Big 10","Big 10","Big 10","SEC","SEC","SEC","SEC",
                                             "SEC", "Midwest Conference","Midwest Conference","Midwest Conference","ACC",
                                             "ACC", "ACC","ACC",
                                             "ACC","ACC","ACC","ACC","ACC","Big 10","Big 10","Big 10","Big 10",
                                             "Big 10","Big 10","CUSA","CUSA","CUSA","CUSA",
                                             "CUSA","CUSA","CUSA","Big 12","Big 12","Big 12","Big 12",
                                             "Big 12","Big 12","Missouri Valley Conference","Big 10","Big 10","Big 10",
                                             "Big 10",
                                             "Big 10","ACC", "ACC", "ACC", "ACC", "ACC", "ACC", "ACC", "ACC"
                                             ))

#tester <- qb_comb %>% select(Name, College, Conference)
```

```{r}
# creation of cv folds
qbcomb_cv <- vfold_cv(qb_comb, v = 10)
```

```{r}
# model spec

#OLS spec
lm_spec <- 
    linear_reg() %>% 
    set_engine(engine = 'lm') %>% 
    set_mode('regression') 

#LASSO spec
lm_lasso_spec <- 
  linear_reg() %>%
  set_args(mixture = 1, penalty = tune()) %>% ## mixture = 1 indicates Lasso, we'll choose penalty later
  set_engine(engine = 'glmnet') %>% 
  set_mode('regression') 
```

```{r}
# recipes & workflows

#OLS recipe
lm_rec <- recipe(Rating ~ Height + Age + Weight + Experience + Conference + hsState + `Passes Attempted` + `Games Played`, data = qb_comb) %>% 
    update_role(`Passes Attempted`, new_role = 'Info') %>%
    update_role(`Games Played`, new_role = 'Info') %>%
    step_filter(`Passes Attempted` >= 50, `Games Played` > 0) %>% #removes potential outliers with few passes
    step_lincomb(all_numeric_predictors()) %>% # removes predictors that are linear combos of others
    step_corr(all_predictors()) %>% #removes highly correlated variables
    step_dummy(all_nominal_predictors()) # creates indicator variables for categorical variables
    

#OLS workflow
lm_wf <- workflow() %>%
  add_recipe(lm_rec) %>%
  add_model(lm_spec)


#LASSO recipe
lasso_rec <- recipe(Rating ~ Height + Age + Weight + Experience + Conference + hsState + `Passes Attempted` + `Games Played`, data = qb_comb) %>%
    update_role(`Passes Attempted` , new_role = 'Info') %>%
    update_role(`Games Played` , new_role = 'Info') %>%
    step_filter(`Passes Attempted` >= 50, `Games Played` > 0) %>% #removes potential outliers with few passes
    step_nzv(all_predictors()) %>% # removes variables with the same value
    step_novel(all_nominal_predictors()) %>% # important if you have rare categorical variables 
    step_normalize(all_numeric_predictors()) %>%  # important standardization step for LASSO
    step_dummy(all_nominal_predictors())  # creates indicator variables for categorical variables
    
ns3_lasso <- lasso_rec %>%
  step_ns(Weight, deg_free = 3) %>% # natural cubic splines (higher deg_free means more knots)
  step_ns(Height, deg_free = 3) %>% 
  step_ns(Age, deg_free = 3) %>% 
  step_ns(Experience, deg_free = 3) %>% 
  step_ns(`Games Played`, deg_free = 2) 
  

#lasso_rec %>% prep(qb_comb) %>% juice()

#LASSO workflow
lasso_wf <- workflow() %>% 
  add_recipe(ns3_lasso) %>%
  add_model(lm_lasso_spec)
```


```{r}
# fit & tune models
lm_lasso_spec_tune <- 
  linear_reg() %>%
  set_args(mixture = 1, penalty = tune()) %>% ## tune() indicates that we will try a variety of values
  set_engine(engine = 'glmnet') %>%
  set_mode('regression') 

lasso_wf <- workflow() %>% 
  add_recipe(ns3_lasso) %>%
  add_model(lm_lasso_spec_tune) 

penalty_grid <- grid_regular(
  penalty(range = c(-5, 3)), #log10 transformed 10^-5 to 10^3
  levels = 50)

tune_res <- tune_grid( # new function for tuning hyperparameters
  lasso_wf, # workflow
  resamples = qbcomb_cv, # folds
  metrics = metric_set(rmse),
  grid = penalty_grid # penalty grid
)

autoplot(tune_res)

collect_metrics(tune_res) %>%
  filter(.metric == 'rmse') %>%
  select(penalty, rmse = mean) 


best_penalty <- select_best(tune_res, metric = 'rmse') # choose best penalty value

final_wf <- finalize_workflow(lasso_wf, best_penalty) # incorporates penalty value to workflow

final_fit <- fit(final_wf, data = qb_comb)

tidy(final_fit)
```

c.

```{r}
#  calculate/collect CV metrics
mod1_cv <- fit_resamples(final_fit,
  resamples = qbcomb_cv, 
  metrics = metric_set(rmse, rsq, mae)
)

mod1_cv %>% collect_metrics()

collect_metrics(tune_res) %>% 
  filter(.metric == "rmse") %>% 
  select(penalty, rmse = mean)
```

 
d.

```{r}
# visual residuals
mod1_output <- qb_comb %>%
    bind_cols(predict(final_fit, new_data = qb_comb)) %>%
    mutate(resid = Rating - .pred)

#Height (non-linearity)
ggplot(mod1_output, aes(x = Height, y = resid)) +
    geom_point() +
    geom_smooth() +
    geom_hline(yintercept = 0, color = "red") + 
    theme_classic() 

#Age (some non-linearity)
ggplot(mod1_output, aes(x = Age, y = resid)) +
    geom_point() +
    geom_smooth() +
    geom_hline(yintercept = 0, color = "red") + 
    theme_classic() 

#Weight (non-linearity)
ggplot(mod1_output, aes(x = Weight, y = resid)) +
    geom_point() +
    geom_smooth() +
    geom_hline(yintercept = 0, color = "red") + 
    theme_classic() 

#Experience (non-linearity)
ggplot(mod1_output, aes(x = Experience, y = resid)) +
    geom_point() +
    geom_smooth() +
    geom_hline(yintercept = 0, color = "red") + 
    theme_classic() 

#College Conference
ggplot(mod1_output, aes(x = Conference, y = resid)) +
    geom_point() +
    geom_smooth() +
    geom_hline(yintercept = 0, color = "red") + 
    theme_classic() 

#High School State
ggplot(mod1_output, aes(x = hsState, y = resid)) +
    geom_point() +
    geom_smooth() +
    geom_hline(yintercept = 0, color = "red") + 
    theme_classic() 

#Passes Attempted (non-linearity)
ggplot(mod1_output, aes(x = `Passes Attempted`, y = resid)) +
    geom_point() +
    geom_smooth() +
    geom_hline(yintercept = 0, color = "red") + 
    theme_classic() 

#Games Played (non-linearity)
ggplot(mod1_output, aes(x = `Games Played`, y = resid)) +
    geom_point() +
    geom_smooth() +
    geom_hline(yintercept = 0, color = "red") + 
    theme_classic() 
```



2. **Accounting for nonlinearity**
    - Update your OLS model(s) and LASSO model to use natural splines for the quantitative predictors.
        - You'll need to update the recipe to include `step_ns()` for each quantitative predictor.
        - It's recommended to use few knots (e.g., 2 knots = 3 degrees of freedom).

    - Compare insights from variable importance analyses here and the corresponding results from the Investigation 1. Now after having accounted for nonlinearity, have the most relevant predictors changed?
        - Note that if some (but not all) of the spline terms are selected in the final models, the whole predictor should be treated as selected.

    - Fit a GAM using spline terms using the set of variables deemed to be most relevant based on your investigations so far.
        - How does test performance of the GAM compare to other models you explored?
        - Do you gain any insights from the GAM output plots for each predictor?

    - Don't worry about KNN for now.
    
    
```{r}
#OLS model with splines

#qb_comb %>% purrr::map(~sum(is.na(.)))

lm_spec <- 
  linear_reg() %>%
  set_engine(engine = 'lm') %>%
  set_mode('regression') 

#OLS recipe
lm_rec <- recipe(Rating ~ Height + Age + Weight + Experience + Conference + hsState + `Passes Attempted` + `Games Played`, data = qb_comb) %>% 
    update_role(`Passes Attempted`, new_role = 'Info') %>%
    update_role(`Games Played`, new_role = 'Info') %>%
    step_filter(`Passes Attempted` >= 50, `Games Played` > 0) %>% #removes potential outliers with few passes
    #step_lincomb(all_numeric_predictors()) %>% # removes predictors that are linear combos of others
    #step_corr(all_numeric_predictors()) %>% #removes highly correlated variables
    step_other(all_nominal_predictors(),threshold = .05)  %>%
    step_dummy(all_nominal_predictors())  # creates indicator variables for categorical variables
   
 
ns3_OLS <- lm_rec %>%
  step_ns(Weight, deg_free = 3) %>% # natural cubic splines (higher deg_free means more knots)
  step_ns(Height, deg_free = 3) %>% 
  step_ns(Age, deg_free = 3) %>% 
  step_ns(Experience, deg_free = 3) %>% 
  step_ns(`Games Played`, deg_free = 2) 
  

#OLS workflow
splines_wf <- workflow() %>%
  add_recipe(ns3_OLS) %>%
  add_model(lm_spec)

fit(splines_wf, data = qb_comb) %>% tidy()

#  calculate/collect CV metrics
splines_cv <- fit_resamples(splines_wf,
  resamples = qbcomb_cv, 
  metrics = metric_set(rmse, rsq, mae))

splines_cv %>% collect_metrics()
```    

<br>

3. **Summarize investigations**
    - Decide on an overall best model based on your investigations so far. To do this, make clear your analysis goals. Predictive accuracy? Interpretability? A combination of both?

<br>

4. **Societal impact**
    - Are there any harms that may come from your analyses and/or how the data were collected?
    - What cautions do you want to keep in mind when communicating your work?
    
    
  We do not believe that there are any real harms that may come from our analyses or the manner in which the data for our project was collected. Our goal for this project is to determine which variables are predictive of an NFL quarterback's passer rating (other than the statistics directly used to calculate passer rating: passing attempts, completions, yards, touchdowns, and interceptions). Our analysis has applications for predicting the end of season passer ratings of current NFL quarterbacks. So, in theory, our analysis could cause harm if it were used by an NFL coaching staff to select which QBs to roster and which to cut (the harm being done to the QBs cut on the basis of our analysis). However, the probability of our analysis ever being used by an NFL coaching staff and the probability of our analysis being the only means by which NFL coaches determine which QBs to roster are both extremely low, mitigating the potential for our analysis to cause harm. The data we are using for our analysis was scraped using Python code from the official NFL website (www.nfl.com), a widely-accessible site, in 2017. 
    When communicating our work, we want to keep in mind the limitations of our analysis. In any sport, and especially in football, there is much more that goes into predicting the performance of a player than quantifiable variables like height, weight, age, or experience. Insofar as this is true, we want our audience to understand that our analysis is only a starting point for predicting the performance of NFL QBs and not an ironclad rule for who will be good and who will not. We would also like to keep in mind the limitations of our data when communicating our work. While our dataset is broad and rich, it does not include all the variables that could potentially predict the passer ratings of NFL QBs. Examples of a few such variables that are not included in our data are: handedness, a measure of the strength of a QB's offensive weapons in a given season, and a measure of the average strength of the defenses faced by a QB in a given season. In summary, we want to ensure our audience understands the limitations of our analysis for predicting NFL QB passer rating as well as the limitations of our data for identifying relevant predictors of passer rating. 



<br><br><br>








