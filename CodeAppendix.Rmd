---
title: "Code Appendix"
author: "Nolan Meyer, Will Orser, Rohit Shah"
date: "12/16/2021"
output:
  html_document:
    toc: yes
    toc_float: yes
  pdf_document:
    toc: yes
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, warning = FALSE, message = FALSE, tidy = TRUE)
```


# Data Cleaning

```{r, eval = TRUE, include=FALSE}
# library statements 
library(dplyr)
library(readr)
library(broom)
library(ggplot2)
library(tidymodels) 
library(tidyverse)
library(probably)
tidymodels_prefer()

set.seed(123)

# Read in data
basic_stats <- read_csv("Basic_Stats.csv")
qb_stats <- read_csv("Career_Stats_Passing.csv")
qb_logs <- read_csv("Game_Logs_Quarterback.csv",na=c("","--","NA"))
```

```{r}
# data cleaning
qb_stats <- qb_stats %>%
    select(-Position)
    
qb_stats <- qb_stats %>%
    rename("Rating" = "Passer Rating")

basic_stats <- basic_stats %>%
    rename("Team" = "Current Team")

basic_stats <- basic_stats %>%
    rename("hsloc" = "High School Location")

basic_stats <- basic_stats %>%
    rename("Weight" = "Weight (lbs)")

basic_stats <- basic_stats %>%
    rename("Height" = "Height (inches)")

basic_stats <- basic_stats %>%
    filter(Position == "QB")

qb_comb <- merge(qb_stats, basic_stats, by="Name")


qb_comb$`Passes Attempted`[which(qb_comb$`Passes Attempted` == '--')] = 0
qb_comb <- qb_comb %>%
  mutate(`Passes Attempted` = as.numeric(`Passes Attempted`)) %>% 
    mutate(`Games Played` = as.numeric(`Games Played`))

qb_comb <- qb_comb %>% select(-c(Number, `Years Played`))


qb_comb <- qb_comb %>% mutate(Experience = as.numeric(stringr::str_extract(Experience,'[0-9]+')))

qb_comb <- qb_comb %>% mutate(hsState = stringr::str_sub(hsloc,-2,-1))

qb_comb <- qb_comb %>% mutate(Conference = c("PAC-12", "PAC-12", "PAC-12", "PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12",
                                             "PAC-12", "PAC-12", "PAC-12", "PAC-12",
                                             "AAC", "AAC", "AAC",
                                             "Big 12", 
                                             "Big 12","Big 12","Big 12","Big 12","Big 12","Big 12",
                                             "Big 10", "Big 10", "Big 10", "Big 10", "Big 10", "Big 10", "Big 10", "Big 10", "Big 10", "Big 10", "Big 10", "Big 10", "Big 10", "Big 10", "Big 10", "Big 10",
                                             "Big 10", "Big 10", "Big 10", "Big 10", "Big 10", "Big 10", "Big 10", "Big 10", "Big 10", "Big 10", "Big 10", "Big 10", "Big 10", "Big 10", "Big 10", "Big 10", "Big 10",
                                             "ACC", "ACC",
                                             "ACC",
                                             "Mountain West", "Mountain West", "Mountain West",
                                             "PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12",
                                             "PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12",
                                             "Big 10",
                                             "Big 10","Big 10","Big 10","Big 10","Big 10",
                                             "SEC", "SEC", "SEC", "SEC", "SEC", "SEC", "SEC", "SEC", "SEC", "SEC", "SEC",
                                             "Big 12", "Big 12", "Big 12", "Big 12", "Big 12", "Big 12",
                                             "Big 12","Big 12","Big 12","Big 12","Big 12","Big 12","Big 12","Big 12",
                                             "CUSA", "CUSA", "CUSA", "CUSA", "CUSA",
                                             "Mountain West", "Mountain West", "Mountain West",
                                             "Ivy","Ivy","Ivy","Ivy","Ivy","Ivy","Ivy","Ivy","Ivy","Ivy","Ivy","Ivy",
                                             "Colonial Athletic Association","Colonial Athletic Association","Colonial Athletic Association","Colonial Athletic Association","Colonial Athletic Association","Colonial Athletic Association","Colonial Athletic Association","Colonial Athletic Association","Colonial Athletic Association",
                                             "PAC-12","PAC-12","PAC-12","PAC-12","PAC-12",
                                             "Big 12","Big 12","Big 12","Big 12","Big 12","Big 12",
                                             "Ohio Valley Conference", "Ohio Valley Conference", "Ohio Valley Conference",
                                             "ACC", "ACC", "ACC", "ACC",
                                             "PAC-12",
                                             "Big 12","Big 12","Big 12","Big 12","Big 12",
                                             "Big 10","Big 10","Big 10","Big 10","Big 10","Big 10","Big 10","Big 10","Big 10",
                                             "ACC", "ACC","ACC","ACC","ACC","ACC","ACC","ACC","ACC","ACC","ACC","ACC","ACC","ACC","ACC",
                                             "PAC-12",
                                             "Big 10","Big 10","Big 10","Big 10","Big 10","Big 10","Big 10","Big 10","Big 10",
                                             "PAC-12","PAC-12",
                                             "Pioneer Football League", "Pioneer Football League", "Pioneer Football League", "Pioneer Football League", "Pioneer Football League", "Pioneer Football League", "Pioneer Football League", "Pioneer Football League", "Pioneer Football League", "Pioneer Football League",
                                             "Big 10",
                                             "Big 12","Big 12","Big 12","Big 12",
                                             "Mountain West","Mountain West","Mountain West","Mountain West","Mountain West","Mountain West",
                                             "AAC","AAC","AAC","AAC","AAC",
                                             "PAC-12",
                                             "ACC","ACC","ACC","ACC","ACC","ACC",
                                             "PAC-12","PAC-12","PAC-12","PAC-12","PAC-12",
                                             "AAC",
                                             "SEC","SEC","SEC","SEC","SEC","SEC","SEC",
                                             "SEC","SEC","SEC","SEC","SEC","SEC","SEC","SEC","SEC","SEC","SEC","SEC","SEC",
                                             "PAC-12","PAC-12",
                                             "ACC", "ACC", "ACC", "ACC",
                                             "PAC-12","PAC-12",
                                             "SEC", "SEC", "SEC",
                                             "Southland Conference", "Southland Conference","Southland Conference","Southland Conference","Southland Conference","Southland Conference","Southland Conference","Southland Conference","Southland Conference","Southland Conference","Southland Conference","Southland Conference","Southland Conference","Southland Conference",
                                             "CUSA", "CUSA", "CUSA", "CUSA","CUSA","CUSA","CUSA","CUSA","CUSA","CUSA","CUSA","CUSA","CUSA", "Big 12",
                                             "Big 12","Big 12","Big 12","Big 12","Big 12","Big 12", "Big 10",
                                             "Big 10","Big 10","Big 10","Mountain West",
                                              "Mountain West", "Mountain West", "Mountain West", "PAC-12",
                                             "PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","ACC",
                                             "ACC", "ACC", "ACC", "SEC",
                                             "SEC","SEC","SEC","SEC","SEC","AAC",
                                             "AAC", "AAC","AAC","AAC","AAC","AAC","AAC","AAC","AAC","AAC","AAC","PAC-12",
                                             "PAC-12","PAC-12","PAC-12","PAC-12","PAC-12",
                                             "PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","Big 12",
                                             "Big 12", "ACC",
                                             "ACC","ACC","ACC","ACC","ACC","SEC",
                                             "ACC",
                                             "ACC","ACC","ACC","ACC","ACC","ACC","ACC","ACC","ACC","ACC","ACC","ACC","PAC-12",
                                             "PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","MAC",
                                             "MAC", "MAC","MAC","MAC","MAC","MAC","MAC","MAC","MAC","MAC","MAC","MAC","ACC",
                                             "ACC","ACC","ACC","ACC","ACC","ACC","ACC","ACC","PAC-12",
                                             "PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","ACC",
                                             "ACC","SEC",
                                             "Big 10",
                                             "Big 10","SEC",
                                             "SEC", "PAC-12",
                                             "PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","PAC-12","Big 12","Big 12","Big 12","Big 12",
                                             "SEC", "SEC", "SEC","SEC",
                                             "SEC","SEC","SEC","SEC","Big 10","Big 10","Big 10","Big 10",
                                             "Big 10","Big 10","Big 10","Big 10","Big 10","SEC","SEC","SEC","SEC",
                                             "SEC", "Midwest Conference","Midwest Conference","Midwest Conference","ACC",
                                             "ACC", "ACC","ACC",
                                             "ACC","ACC","ACC","ACC","ACC","Big 10","Big 10","Big 10","Big 10",
                                             "Big 10","Big 10","CUSA","CUSA","CUSA","CUSA",
                                             "CUSA","CUSA","CUSA","Big 12","Big 12","Big 12","Big 12",
                                             "Big 12","Big 12","Missouri Valley Conference","Big 10","Big 10","Big 10",
                                             "Big 10",
                                             "Big 10","ACC", "ACC", "ACC", "ACC", "ACC", "ACC", "ACC", "ACC"
                                             ))

#tester <- qb_comb %>% select(Name, College, Conference)

qb_logs <- qb_logs %>% 
  filter(Season != "Preseason", Outcome != "T", `Games Started` == 1) %>% 
  select(-c(Position, Week, `Game Date`, Score, `Games Played`, `Games Started`, Name, `Player Id`, Year, Season, Opponent, `Home or Away`))

qb_logs$Outcome <- as.factor(qb_logs$Outcome) 

qb_logs <- qb_logs %>% 
  mutate(Outcome = relevel(Outcome, ref='L')) #set reference level to be L

qb_logs[is.na(qb_logs)] = 0  #replaces NA values with 0
```


# Regression

```{r}
# creation of cv folds
qbcomb_cv <- vfold_cv(qb_comb, v = 10)
```


## LASSO (No Splines) 

```{r}
#Model spec. Fit & tune LASSO model
lm_lasso_spec_tune <- 
  linear_reg() %>%
  set_args(mixture = 1, penalty = tune()) %>% ## tune() indicates that we will try a variety of values
  set_engine(engine = 'glmnet') %>%
  set_mode('regression') 


#LASSO recipe
lasso_rec <- recipe(Rating ~ Height + Age + Weight + Experience + Conference + hsState + `Passes Attempted` + `Games Played`, data = qb_comb) %>%
    update_role(`Passes Attempted` , new_role = 'Info') %>%
    update_role(`Games Played` , new_role = 'Info') %>%
    step_filter(`Passes Attempted` >= 50, `Games Played` > 0) %>% #removes potential outliers with few passes
    step_nzv(all_predictors()) %>% # removes variables with the same value
    step_novel(all_nominal_predictors()) %>% # important if you have rare categorical variables 
    step_normalize(all_numeric_predictors()) %>%  # important standardization step for LASSO
    step_dummy(all_nominal_predictors())  # creates indicator variables for categorical variables

#LASSO workflow
lasso_wf <- workflow() %>% 
  add_recipe(lasso_rec) %>%
  add_model(lm_lasso_spec_tune) 

penalty_grid <- grid_regular(
  penalty(range = c(-5, 3)), #log10 transformed 10^-5 to 10^3
  levels = 50)

tune_res <- tune_grid( # new function for tuning hyperparameters
  lasso_wf, # workflow
  resamples = qbcomb_cv, # folds
  metrics = metric_set(rmse),
  grid = penalty_grid) # penalty grid

autoplot(tune_res)

collect_metrics(tune_res) %>%
  filter(.metric == 'rmse') %>%
  select(penalty, rmse = mean) 

best_penalty <- select_best(tune_res, metric = 'rmse') # choose best penalty value

final_wf <- finalize_workflow(lasso_wf, best_penalty) # incorporates penalty value to workflow

final_fit0 <- fit(final_wf, data = qb_comb)

output <- tidy(final_fit0) 

output %>% arrange(desc(estimate)) #sort variables in the LASSO w/o splines model by coefficient value (a way of measuring variable importance)
```

### CV Metrics

```{r}
#  calculate/collect CV metrics
mod2_cv <- fit_resamples(final_fit0,
  resamples = qbcomb_cv, 
  metrics = metric_set(rmse, rsq, mae))

mod2_cv %>% collect_metrics()

#LASSO w/o splines is a far less accurate predictor of QB rating than the LASSO w/ splines model
```

## LASSO w/ Splines

```{r}
# recipes & workflows

#LASSO recipe
lasso_rec <- recipe(Rating ~ Height + Age + Weight + Experience + Conference + hsState + `Passes Attempted` + `Games Played`, data = qb_comb) %>%
    update_role(`Passes Attempted` , new_role = 'Info') %>%
    update_role(`Games Played` , new_role = 'Info') %>%
    step_filter(`Passes Attempted` >= 50, `Games Played` > 0) %>% #removes potential outliers with few passes
    step_nzv(all_predictors()) %>% # removes variables with the same value
    step_novel(all_nominal_predictors()) %>% # important if you have rare categorical variables 
    step_normalize(all_numeric_predictors()) %>%  # important standardization step for LASSO
    step_dummy(all_nominal_predictors())  # creates indicator variables for categorical variables

#Adding natural cubic splines to LASSO recipe    
ns3_lasso <- lasso_rec %>%
  step_ns(Weight, deg_free = 3) %>% # natural cubic splines (higher deg_free means more knots)
  step_ns(Height, deg_free = 3) %>% 
  step_ns(Age, deg_free = 3) %>% 
  step_ns(Experience, deg_free = 3) %>% 
  step_ns(`Games Played`, deg_free = 2) 

#LASSO workflow
lasso_wf <- workflow() %>% 
  add_recipe(ns3_lasso) %>%
  add_model(lm_lasso_spec_tune)
```


```{r}
# fit & tune LASSO model
lm_lasso_spec_tune <- 
  linear_reg() %>%
  set_args(mixture = 1, penalty = tune()) %>% ## tune() indicates that we will try a variety of values
  set_engine(engine = 'glmnet') %>%
  set_mode('regression') 

lasso_wf <- workflow() %>% 
  add_recipe(ns3_lasso) %>%
  add_model(lm_lasso_spec_tune) 

penalty_grid <- grid_regular(
  penalty(range = c(-5, 3)), #log10 transformed 10^-5 to 10^3
  levels = 50)

tune_res <- tune_grid( # new function for tuning hyperparameters
  lasso_wf, # workflow
  resamples = qbcomb_cv, # folds
  metrics = metric_set(rmse),
  grid = penalty_grid # penalty grid
)

autoplot(tune_res)

collect_metrics(tune_res) %>%
  filter(.metric == 'rmse') %>%
  select(penalty, rmse = mean) 


best_penalty <- select_best(tune_res, metric = 'rmse') # choose best penalty value

final_wf <- finalize_workflow(lasso_wf, best_penalty) # incorporates penalty value to workflow

final_fit <- fit(final_wf, data = qb_comb)

output <- tidy(final_fit) 

output %>% arrange(desc(estimate)) #sort variables in the LASSO w/ splines model by coefficient value (a way of measuring variable importance)
```


### CV Metrics

```{r}
#  calculate/collect CV metrics
mod1_cv <- fit_resamples(final_fit,
  resamples = qbcomb_cv, 
  metrics = metric_set(rmse, rsq, mae))

mod1_cv %>% collect_metrics()

#LASSO w/ Splines is a far better model for predicting QB passer rating than the ordinary LASSO model.
```

 
## OLS Residual Evaluation

```{r}
# visual residuals
mod1_output <- qb_comb %>%
    bind_cols(predict(final_fit, new_data = qb_comb)) %>%
    mutate(resid = Rating - .pred) %>% 
    filter(`Passes Attempted` >= 50, `Games Played` > 0)

#Height (non-linearity)
ggplot(mod1_output, aes(x = Height, y = resid)) +
    geom_point() +
    geom_smooth() +
    geom_hline(yintercept = 0, color = "red") + 
    theme_classic() 

#Age (some non-linearity)
ggplot(mod1_output, aes(x = Age, y = resid)) +
    geom_point() +
    geom_smooth() +
    geom_hline(yintercept = 0, color = "red") + 
    theme_classic() 

#Weight (non-linearity)
ggplot(mod1_output, aes(x = Weight, y = resid)) +
    geom_point() +
    geom_smooth() +
    geom_hline(yintercept = 0, color = "red") + 
    theme_classic() 

#Experience (non-linearity)
ggplot(mod1_output, aes(x = Experience, y = resid)) +
    geom_point() +
    geom_smooth() +
    geom_hline(yintercept = 0, color = "red") + 
    theme_classic() 

#College Conference
ggplot(mod1_output, aes(x = Conference, y = resid)) +
    geom_point() +
    geom_smooth() +
    geom_hline(yintercept = 0, color = "red") + 
    theme_classic() 

#High School State
ggplot(mod1_output, aes(x = hsState, y = resid)) +
    geom_point() +
    geom_smooth() +
    geom_hline(yintercept = 0, color = "red") + 
    theme_classic() 

#Passes Attempted (non-linearity)
ggplot(mod1_output, aes(x = `Passes Attempted`, y = resid)) +
    geom_point() +
    geom_smooth() +
    geom_hline(yintercept = 0, color = "red") + 
    theme_classic() 

#Games Played (non-linearity)
ggplot(mod1_output, aes(x = `Games Played`, y = resid)) +
    geom_point() +
    geom_smooth() +
    geom_hline(yintercept = 0, color = "red") + 
    theme_classic() 
```


## OLS Model (No Splines)

```{r}
#OLS model spec
lm_spec <- 
  linear_reg() %>%
  set_engine(engine = 'lm') %>%
  set_mode('regression') 
    
#OLS recipe
lm_rec <- recipe(Rating ~ Height + Age + Weight + Experience + Conference + hsState + `Passes Attempted` + `Games Played`, data = qb_comb) %>% 
    update_role(`Passes Attempted`, new_role = 'Info') %>%
    update_role(`Games Played`, new_role = 'Info') %>%
    step_filter(`Passes Attempted` >= 50, `Games Played` > 0) %>% #removes potential outliers with few passes
    #step_lincomb(all_numeric_predictors()) %>% # removes predictors that are linear combos of others
    #step_corr(all_numeric_predictors()) %>% #removes highly correlated variables
    step_other(all_nominal_predictors(),threshold = .05)  %>%
    step_dummy(all_nominal_predictors())  # creates indicator variables for categorical variables

#OLS workflow
lm_wf <- workflow() %>%
  add_recipe(lm_rec) %>%
  add_model(lm_spec)

fit(lm_wf, data = qb_comb) %>% tidy()
```

### CV Metrics

```{r}
#calculate/collect CV metrics
lm_cv <- fit_resamples(lm_wf,
  resamples = qbcomb_cv, 
  metrics = metric_set(rmse, rsq, mae))

lm_cv %>% collect_metrics()

#OLS (no splines) is a far worse predictor of QB passer rating than an OLS model incorporating natural cubic splines.
```

    
## OLS Model w/ Splines  

```{r}
#qb_comb %>% purrr::map(~sum(is.na(.)))

lm_spec <- 
  linear_reg() %>%
  set_engine(engine = 'lm') %>%
  set_mode('regression') 

#OLS recipe
lm_rec <- recipe(Rating ~ Height + Age + Weight + Experience + Conference + hsState + `Passes Attempted` + `Games Played`, data = qb_comb) %>% 
    update_role(`Passes Attempted`, new_role = 'Info') %>%
    update_role(`Games Played`, new_role = 'Info') %>%
    step_filter(`Passes Attempted` >= 50, `Games Played` > 0) %>% #removes potential outliers with few passes
    #step_lincomb(all_numeric_predictors()) %>% # removes predictors that are linear combos of others
    #step_corr(all_numeric_predictors()) %>% #removes highly correlated variables
    step_other(all_nominal_predictors(),threshold = .05)  %>%
    step_dummy(all_nominal_predictors())  # creates indicator variables for categorical variables
   
 
ns3_OLS <- lm_rec %>%
  step_ns(Weight, deg_free = 3) %>% # natural cubic splines (higher deg_free means more knots)
  step_ns(Height, deg_free = 3) %>% 
  step_ns(Age, deg_free = 3) %>% 
  step_ns(Experience, deg_free = 3) %>% 
  step_ns(`Games Played`, deg_free = 2) 
  

#OLS workflow
splines_wf <- workflow() %>%
  add_recipe(ns3_OLS) %>%
  add_model(lm_spec)

fit(splines_wf, data = qb_comb) %>% tidy()
```

### CV Metrics

```{r}
#calculate/collect CV metrics
splines_cv <- fit_resamples(splines_wf,
  resamples = qbcomb_cv, 
  metrics = metric_set(rmse, rsq, mae))

splines_cv %>% collect_metrics()
```    



# Classification

```{r, eval = TRUE, include = FALSE, echo=FALSE}
# library statements 
# read in data
library(dplyr)
library(readr)
library(broom)
library(ggplot2)
library(tidymodels) 
library(tidyverse)
library(probably)
tidymodels_prefer() # Resolves conflicts, prefers tidymodel functions

set.seed(123)

basic_stats <- read_csv("Basic_Stats.csv")
qb_stats <- read_csv("Career_Stats_Passing.csv")
punt_return <- read_csv("Career_Stats_Punt_Return.csv")
punting <- read_csv("Career_Stats_Punting.csv")
receiving <- read_csv("Career_Stats_Receiving.csv")
kickers <- read_csv("Game_Logs_Kickers.csv")
oline_logs <- read_csv("Game_Logs_Offensive_Line.csv")
punters_logs <- read_csv("Game_Logs_Punters.csv")
qb_logs <- read_csv("Game_Logs_Quarterback.csv",na=c("","--","NA"))
rb_logs <- read_csv("Game_Logs_Runningback.csv")
wrandte_logs <- read_csv("Game_Logs_Wide_Receiver_and_Tight_End.csv")
```

```{r, echo=FALSE}
# data cleaning
qb_stats <- qb_stats %>%
    select(-Position)
    
qb_stats <- qb_stats %>%
    rename("Rating" = "Passer Rating")

basic_stats <- basic_stats %>%
    rename("Team" = "Current Team")

basic_stats <- basic_stats %>%
    rename("hsloc" = "High School Location")

basic_stats <- basic_stats %>%
    rename("Weight" = "Weight (lbs)")

basic_stats <- basic_stats %>%
    rename("Height" = "Height (inches)")

basic_stats <- basic_stats %>%
    filter(Position == "QB")

qb_comb <- merge(qb_stats, basic_stats, by="Name")


qb_comb$`Passes Attempted`[which(qb_comb$`Passes Attempted` == '--')] = 0
qb_comb <- qb_comb %>%
  mutate(`Passes Attempted` = as.numeric(`Passes Attempted`)) %>% 
    mutate(`Games Played` = as.numeric(`Games Played`))

qb_comb <- qb_comb %>% select(-c(Number, `Years Played`))


qb_comb <- qb_comb %>% mutate(Experience = as.numeric(stringr::str_extract(Experience,'[0-9]+')))


#qb_comb$hsloc
#####################

qb_logs <- qb_logs %>% 
  filter(Season != "Preseason", Outcome != "T", `Games Started` == 1) %>% 
  select(-c(Position, Week, `Game Date`, Score, `Games Played`, `Games Started`, Name, `Player Id`, Year, Season, Opponent, `Home or Away`))

qb_logs$Outcome <- as.factor(qb_logs$Outcome) 

qb_logs <- qb_logs %>% 
  mutate(Outcome = relevel(Outcome, ref='L')) #set reference level to be L

qb_logs[is.na(qb_logs)] = 0  #replaces NA values with 0
```


## Logistic Regression Model

```{r}
logistic_mod <- logistic_reg() %>%
    set_engine("glm") %>%
    set_mode('classification')

outcome_rec <- recipe(Outcome ~ ., data = qb_logs) %>%
  step_normalize(all_numeric_predictors())

logistic_mod_fit <- workflow() %>%
  add_model(logistic_mod) %>%
  add_recipe(outcome_rec) %>%
  fit(data = qb_logs)
```

```{r}
logistic_mod_fit %>%
  tidy() # Model Coefficients from Trained Model

library(dotwhisker)
tidy(logistic_mod_fit) %>%  # Viz of Trained Model Odds Ratios
  mutate(conf.low = exp(estimate - 1.96*std.error),conf.high = exp(estimate + 1.96*std.error)) %>% # do this first
  mutate(estimate = exp(estimate)) %>% # this second
  dwplot(dot_args = list(size = 2, color = "black"),
         whisker_args = list(color = "black"),
         vline = geom_vline(xintercept = 1, color = "grey50", linetype = 2)) + 
  labs(x = 'Odds Ratio') + 
  theme_classic()
```


### Soft Predictions

```{r}
# Soft Predictions: Predicted Probabilities
logistic_output <-  qb_logs %>%
  bind_cols(predict(logistic_mod_fit, new_data = qb_logs, type = 'prob')) 

logistic_output %>% head()
```

```{r}
# Visualize predicted probabilities as a function of true outcome
logistic_output %>%
  ggplot(aes(x = Outcome, y = .pred_W)) +
  geom_boxplot() + 
  geom_hline(yintercept = 0.5, color='red') + 
  labs(y = 'Predicted Probability of Winning', x = 'Observed Outcome (L or W)') +
  theme_classic()
```


### Hard Predictions 

```{r}
logistic_output %>%
  ggplot(aes(x = Outcome, y = .pred_L)) +
  geom_boxplot() + 
  geom_hline(yintercept = 0.5, color='red') + 
  labs(y = 'Predicted Probability of LOSING', x = 'Observed Outcome (L or W)') +
  theme_classic()

logistic_output <- logistic_output %>%
  mutate(.pred_class = make_two_class_pred(.pred_L, levels(Outcome), threshold = .5)) #77.1 accuracy

#head(logistic_output)

#logistic_output %>%
#  count(Outcome, .pred_class)

logistic_output %>%
  conf_mat(truth = Outcome, estimate = .pred_class)
```


### CV Accuracy Metrics

```{r}
set.seed(1512)
qblogs_cv10 <- vfold_cv(qb_logs, v=10)

# CV Fit Model
log_cv_fit <- fit_resamples(
    logistic_mod_fit, 
    resamples = qblogs_cv10,
    metrics = metric_set(sens, yardstick::spec, accuracy, roc_auc),
    control = control_resamples(save_pred = TRUE, event_level = 'second'))  # you need predictions for ROC calculations

collect_metrics(log_cv_fit) #default threshold is 0.5
```


## Random Forest Model

```{r}
outcome_rf_rec <- recipe(Outcome ~ ., data = qb_logs) %>%
  step_normalize(all_numeric_predictors())

rf_spec <- rand_forest() %>%
  set_engine(engine = 'ranger') %>% 
  set_args(mtry = NULL, # size of random subset of variables; default is floor(sqrt(ncol(x)))
           trees = 100, # Number of bags
           min_n = 5,
           probability = FALSE, # want hard predictions first
           importance = 'impurity') %>% 
  set_mode('classification') # change this for regression tree

rf_spec


outcome_rf_wf <- workflow() %>%
  add_model(rf_spec) %>%
  add_recipe(outcome_rf_rec)
```


```{r}
set.seed(123)
outcome_rf_fit <- outcome_rf_wf %>%
  fit(data = qb_logs)

outcome_rf_fit # check out OOB prediction error (accuracy = 1 - OOB prediction error)
```


### OOB Error

```{r}
outcome_rf_OOB_output <- tibble(
  .pred_class = outcome_rf_fit %>% extract_fit_engine() %>% pluck('predictions'),
  Outcome = qb_logs %>% pull(Outcome))

bag_metrics <- metric_set(sens, yardstick::spec, accuracy)

outcome_rf_OOB_output %>% 
  bag_metrics(truth = Outcome, estimate = .pred_class)

outcome_rf_OOB_output %>% 
  conf_mat(truth = Outcome, estimate = .pred_class)
```


### AUC

```{r}
set.seed(123) #to get the same bootstrap samples, use same seed
outcome_rf_fit2 <- outcome_rf_wf %>%
  update_model(rf_spec %>% set_args(probability = TRUE)) %>%
  fit(data = qb_logs)

outcome_rf_fit2
```

```{r}
outcome_rf_OOB_output2 <- bind_cols(
  outcome_rf_fit2 %>% extract_fit_engine() %>% pluck('predictions') %>% as_tibble(),
  qb_logs %>% select(Outcome))

outcome_rf_OOB_output2 %>% 
  roc_curve(Outcome, W, event_level = "second") %>% autoplot()

outcome_rf_OOB_output2 %>% 
  roc_auc(Outcome, W, event_level = "second") #Area under Curve
```


### Variable Importance

```{r}
library(vip) #install.packages('vip')

outcome_rf_fit %>% extract_fit_engine() %>% vip() #based on impurity

outcome_rf_wf %>% #based on permutation
  update_model(rf_spec %>% set_args(importance = "permutation")) %>%
  fit(data = qb_logs) %>% extract_fit_engine() %>% vip()
```

## Model Comparison

```{r}
collect_metrics(log_cv_fit) #CV Logistic Model


outcome_rf_OOB_output %>%  #RF OOB Accuracy
  bag_metrics(truth = Outcome, estimate = .pred_class)
outcome_rf_OOB_output2 %>%  #RF AUC
  roc_auc(Outcome, W, event_level = "second")
```



# Clustering

## Dendrograms 

```{r}
# Select the variables to be used in clustering
qb_logs_sub <- qb_logs %>%
    select(-Outcome)

# Summary statistics for the variables
summary(qb_logs_sub)

# Compute a distance matrix on the scaled data
dist_mat_scaled <- dist(scale(qb_logs_sub))

# The (scaled) distance matrix is the input to hclust()
# The method argument indicates the linkage type
hc_complete <- hclust(dist_mat_scaled, method = "complete")
hc_single <- hclust(dist_mat_scaled, method = "single")
hc_average <- hclust(dist_mat_scaled, method = "average")
hc_centroid <- hclust(dist_mat_scaled, method = "centroid")

# Plot dendrograms
plot(hc_complete)
plot(hc_single)
plot(hc_average)
plot(hc_centroid)
```

```{r}
qb_logs <- qb_logs %>%
    mutate(
        hclust_height3 = factor(cutree(hc_complete, h = 3)), # Cut at height (h) 3
        hclust_num6 = factor(cutree(hc_complete, k = 4)) # Cut into 4 clusters (k)
    )

plot(hc_complete, labels = qb_logs$hclust_height3)
plot(hc_complete, labels = qb_logs$hclust_num6)

```

## PCA

```{r}
mat <- qb_logs %>%
  select(-Outcome,-hclust_height3,-hclust_num6) %>%
  as.matrix()

pca_out <- prcomp(mat, center = TRUE, scale = TRUE)
pca_out %>% pluck('rotation') %>% head()


pca_out_plot <- pca_out %>% pluck('x') %>% as.data.frame() %>% select(PC1,PC2) %>% bind_cols(
  
  tibble(cluster = qb_logs$hclust_num6, Outcome = qb_logs$Outcome)
)

```

```{r, results='hide'}
pca_out %>% head()
```

### Loadings

```{r}
pca_out$rotation %>% as.data.frame() %>% select(PC1) %>%
    arrange(desc(abs(PC1)))

pca_out$rotation %>% as.data.frame() %>% select(PC2) %>%
    arrange(desc(abs(PC2)))
```

### Plots

```{r}
pca_out %>% 
    pluck('x') %>%
    as.data.frame() %>%
    mutate(labels = qb_logs$Outcome) %>%
    ggplot(aes(x = PC1, y = PC2, color = factor(labels))) + 
    geom_point() +
    labs(x = 'PC1', y = 'PC2') +
    scale_color_viridis_d() +
    theme_classic()

pca_out %>% 
    pluck('x') %>%
    as.data.frame() %>%
    mutate(labels = qb_logs$hclust_num6) %>%
    ggplot(aes(x = PC1, y = PC2, color = factor(labels))) + 
    geom_point() +
    labs(x = 'PC1', y = 'PC2') +
    scale_color_viridis_d() +
    theme_classic()
```

```{r}
var_explained <- (pca_out %>% pluck('sdev'))^2
pve <- var_explained/sum(var_explained)

var_data <- tibble(
    PC = seq_len(length(var_explained)),
    var_explained = var_explained,
    pve = pve
)
    
# Construct scree plots
p1 <- var_data %>%
    ggplot(aes(x = PC, y = pve)) +
    geom_point() + 
    geom_line() + 
    labs(x = 'Principal Component', y = 'Proportion of varinace explained') +
    theme_classic()

p2 <- var_data %>%
    ggplot(aes(x = PC, y = cumsum(pve))) +
    geom_point() + 
    geom_line() + 
    labs(x = 'Principal Component', y = 'Cumulative proportion of variance explained') +
    theme_classic()

library(ggpubr) 
ggarrange(p1, p2)

```

